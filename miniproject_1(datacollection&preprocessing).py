# -*- coding: utf-8 -*-
"""MiniProject_1(DataCollection&Preprocessing).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFkTzej0pJknWl3TuBVan2qDlb0gA8sI

# **Requirements**
"""

#pip install --upgrade google-api-python-client

"""# **Importing Libraries**"""

from googleapiclient.discovery import build
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""# **Getting API Key & Channel ID**

"""

#getting api key from google developers console website...
#Goto Google cloud console and then search for youtube api v3
# enable the youtube api v3
#select enabled apis & services then choose youtube api v3
#In that goto this "Credentials compatible with this API" beside that create credentials
#Under that select the API key and copy that

api_key = "AIzaSyAXusAn-yy-2jxZSvbSKl1Up12VleQEcdM"
channel_id = "UCnz-ZXXER4jOvuED5trXfEA"
channel_ids = [
    'UCnz-ZXXER4jOvuED5trXfEA',  # techTFQ
    'UCLLw7jmFsvfIVaUFsLs8mlQ',  # Luke Barousse
    'UCiT9RITQ9PW6BhXK0y2jaeg',  # Ken Jee
    'UC7cs8q-gJRlGwj4A8OmCmXg',  # Alex the analyst
    'UC2UXDak6o7rBm23k3Vv5dww'   # Tina Huang
]

"""# **Creating & getting the Youtube Service**"""

youtube = build("youtube","v3",developerKey = api_key)

"""# **Extracting the Channel Details**

"""

def get_channel_stats(youtube, channel_id):
    # Code to access the YouTube API
    request = youtube.channels().list(
        part="snippet,contentDetails,statistics",
        id=channel_id
    )
    response = request.execute()
    # to store the details
    data = dict(Channel_name = response['items'][0]['snippet']['title'],
                 Subscribers = response['items'][0]['statistics']['subscriberCount'],
                 Views = response['items'][0]['statistics']['viewCount'],
                 Total_videos = response['items'][0]['statistics']['videoCount'])
    return data
    #return response

get_channel_stats(youtube,channel_id)
#the output will be similar to json format,so to read the deatils more clearly use Json formatter & Validator

"""# **Extracting multiple channel details**

"""

def get_channels_stats(youtube, channel_ids):
    # Code to access the YouTube API
    all_data = []
    request = youtube.channels().list(
        part="snippet,contentDetails,statistics",
        id=','.join(channel_ids)
    )

    response = request.execute()
    for i in range(len(response['items'])):
      dataa = dict(Channel_name = response['items'][i]['snippet']['title'],
                Subscribers = response['items'][i]['statistics']['subscriberCount'],
                Views = response['items'][i]['statistics']['viewCount'],
                Total_videos = response['items'][i]['statistics']['videoCount'])
      all_data.append(dataa)
    return all_data

get_channels_stats(youtube,channel_ids)

"""# **Processing the Channels data**"""

# Extract channel statistics
channels_statistics =  get_channels_stats(youtube,channel_ids)
channels_data = pd.DataFrame(channels_statistics)
channels_data

print(channels_data.dtypes)

# Convert string columns to numeric
channels_data['Subscribers'] = pd.to_numeric(channels_data['Subscribers'])
channels_data['Views'] = pd.to_numeric(channels_data['Views'])
channels_data['Total_videos'] = pd.to_numeric(channels_data['Total_videos'])

# Check data types
print(channels_data.dtypes)

"""#**Visualization of Channels Data**

"""

#to know which channel has the highest subscribers
# Set a color palette
colors = sns.color_palette("husl", len(channels_data))

# Create the bar plot
plt.figure(figsize=(5, 5))
highest_subscribers_channel = sns.barplot(
    x='Channel_name',
    y='Subscribers',
    data=channels_data,
    palette=colors,
    width=0.5
)

# Center the plot
plt.gca().set_xlim(left=-0.5, right=len(channels_data) - 0.1)

# Customize the plot
highest_subscribers_channel.set_title('Channel with Highest Subscribers')
highest_subscribers_channel.set_xticklabels(highest_subscribers_channel.get_xticklabels(), rotation=45, ha='right')
highest_subscribers_channel.set_xlabel('Channel Name')
highest_subscribers_channel.set_ylabel('Subscribers(in lakhs)')

# Show the plot
plt.show()

# Convert Views to lakhs
channels_data['Views_Lakhs'] = channels_data['Views'] / 100000

# Set a color palette
colors = sns.color_palette("Dark2", len(channels_data))

# Create the bar plot for views
plt.figure(figsize=(5, 5))
highest_views_channel = sns.barplot(
    x='Channel_name',
    y='Views_Lakhs',
    data=channels_data,
    palette=colors,
    width=0.4
)

# Center the plot
plt.gca().set_xlim(left=-0.5, right=len(channels_data) - 0.5)

# Customize the plot
highest_views_channel.set_title('Channel with Highest Views (in Lakhs)')
highest_views_channel.set_xticklabels(highest_views_channel.get_xticklabels(), rotation=45, ha='right')
highest_views_channel.set_xlabel('Channel Name')
highest_views_channel.set_ylabel('Views (in Lakhs)')

# Format y-axis ticks to display lakhs
plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: "{:,.0f}".format(x)))

# Show the plot
plt.show()

# Set a color palette
colors = sns.color_palette("Set2", len(channels_data))

# Create the bar plot for views
plt.figure(figsize=(5, 5))
highest_views_channel = sns.barplot(
    x='Channel_name',
    y='Total_videos',
    data=channels_data,
    palette=colors,
    width=0.4
)

# Center the plot
plt.gca().set_xlim(left=-0.5, right=len(channels_data) - 0.5)

# Customize the plot
highest_views_channel.set_title('Channel with Highest Videos')
highest_views_channel.set_xticklabels(highest_views_channel.get_xticklabels(), rotation=45, ha='right')
highest_views_channel.set_xlabel('Channel Name')
highest_views_channel.set_ylabel('Total_videos')

# Show the plot

plt.show()

"""# **Getting the Video IDs**"""

#Getting the video(uploads) Id to extract the video details
def get_channels_stats(youtube, channel_ids):
    # Code to access the YouTube API
    all_data = []
    request = youtube.channels().list(
        part="snippet,contentDetails,statistics",
        id=','.join(channel_ids)
    )

    response = request.execute()
    for i in range(len(response['items'])):
      dataa = dict(Channel_name = response['items'][i]['snippet']['title'],
                Subscribers = response['items'][i]['statistics']['subscriberCount'],
                Views = response['items'][i]['statistics']['viewCount'],
                Total_videos = response['items'][i]['statistics']['videoCount'],
                Playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])
      all_data.append(dataa)
    return all_data

channel_statistics = get_channels_stats(youtube,channel_ids)
channel_data = pd.DataFrame(channel_statistics)
channel_data

#To get the playlist id from the channel data

# Check if there are any rows matching the condition
if not channel_data.empty:
    # Get the playlist id from the channel data
    Playlist_id = channel_data.loc[channel_data['Channel_name'] == 'Alex The Analyst', 'Playlist_id'].iloc[0]
    print("Playlist ID:", Playlist_id)
else:
    print("No data found for the specified channel name.")

#Function to get the video ids of the particular ID

def get_video_ids(youtube, Playlist_id):
    request = youtube.playlistItems().list(
        part='contentDetails',
        playlistId=Playlist_id,
        maxResults = 50
    )
    response = request.execute()

    video_ids = []
    for i in range(len(response['items'])):
      video_ids.append(response['items'][i]['contentDetails']['videoId'])

    next_page_token = response.get('nextPageToken')
    more_pages = True

    while more_pages:
      if next_page_token is None:
        more_pages = False
      else:
        request = youtube.playlistItems().list(
            part = 'contentDetails',
            playlistId = Playlist_id,
            maxResults = 50,
            pageToken = next_page_token)
        response = request.execute()

        for i in range(len(response['items'])):
          video_ids.append(response['items'][i]['contentDetails']['videoId'])

        next_page_token = response.get('nextPageToken')

    return video_ids
video_ids = get_video_ids(youtube, Playlist_id)
video_ids

#Function to get the video ids

def get_video_ids(youtube,Playlist_id):
  request = youtube.playlistItems().list(
      part='contentDetails',
      playlistId = Playlist_id,
      maxResults = 50 #to get 50 results for page
  )

  response = request.execute()
  return response
get_video_ids(youtube,Playlist_id) ###output is in json format


## by using this we can get the next token info which is used to track all the video details

def get_video_ids(youtube, Playlist_id):
    request = youtube.playlistItems().list(
        part='contentDetails',
        playlistId=Playlist_id,
        maxResults = 50
    )
    response = request.execute()

    video_ids = []
    for i in range(len(response['items'])):
      video_ids.append(response['items'][i]['contentDetails']['videoId'])

    return len(video_ids)


get_video_ids(youtube, Playlist_id)

#by using the nextpage token extracting the all video_ids

def get_video_ids(youtube, Playlist_id):
    request = youtube.playlistItems().list(
        part='contentDetails',
        playlistId=Playlist_id,
        maxResults = 50
    )
    response = request.execute()

    video_ids = []
    for i in range(len(response['items'])):
      video_ids.append(response['items'][i]['contentDetails']['videoId'])

    next_page_token = response.get('nextPageToken')
    more_pages = True

    while more_pages:
      if next_page_token is None:
        more_pages = False
      else:
        request = youtube.playlistItems().list(
            part = 'contentDetails',
            playlistId = Playlist_id,
            maxResults = 50,
            pageToken = next_page_token)
        response = request.execute()

        for i in range(len(response['items'])):
          video_ids.append(response['items'][i]['contentDetails']['videoId'])

        next_page_token = response.get('nextPageToken')

    return len(video_ids)
No_of_videoIds = get_video_ids(youtube, Playlist_id)
No_of_videoIds

"""  # **Getting all the VIDEO DETAILS**"""

def get_video_details(youtube,video_ids):

  request = youtube.videos().list(
      part = 'snippet,statistics',
      id = ','.join(video_ids[:50])
      )
  response = request.execute()

  return response

  get_video_details(youtube,video_ids)
  #gets all the video details in json format

def get_video_details(youtube,video_ids):

  all_video_statistics = []

  for i in range(0,len(video_ids),50):
    request = youtube.videos().list(
        part = 'snippet,statistics',
         id = ','.join(video_ids[i:i+50]) #fetches from (0 to 50 ,50 to 100,...)
        )
    response = request.execute() # has only 50 details so need to store all

    for video in response['items']:
      video_statistics = dict(Title = video['snippet']['title'],
                            Published_date = video['snippet']['publishedAt'],
                            Views = video['statistics'].get('viewCount', 0),
                            Likes=video['statistics'].get('likeCount', 0),
                           # Dislikes= video['statistics'].get('dislikeCount', 0),
                            Comments= video['statistics'].get('commentCount', 0)
                            )
      all_video_statistics.append(video_statistics)

  return all_video_statistics

all_video_statistics = get_video_details(youtube,video_ids)
all_video_statistics
#got data in dictionary

"""# **Processing the Video Details**"""

all_video_statistics = get_video_details(youtube,video_ids)
all_video_data = pd.DataFrame(all_video_statistics)
all_video_data

# Display the first few rows of the DataFrame
all_video_data.head()

# Summary Statistics
all_video_data.describe()

# Check for Missing Values
all_video_data.isnull().sum()

#Converting the columns to appropriate data types is crucial for performing accurate and efficient analysis
#Converting Published Date to Date Format
#Convert Views to Numeric
#Convert Likes to Numeric
#Convert Comments to Numeric

all_video_data['Published_date'] = pd.to_datetime(all_video_data['Published_date']).dt.date
all_video_data['Views'] = pd.to_numeric(all_video_data['Views'])
all_video_data['Likes'] = pd.to_numeric(all_video_data['Likes'])
#all_video_data['Dislikes'] = pd.to_numeric(all_video_data['Dislikes'])
all_video_data['Comments'] = pd.to_numeric(all_video_data['Comments'])
all_video_data

top10_videos = all_video_data.sort_values(by='Views',ascending=False).head(10)
top10_videos

"""# **Visualising the Video Details**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'top10_videos' is your DataFrame and 'Views' column contains view counts
top10_videos['Views_in_lakhs'] = top10_videos['Views'] / 100000

# Create the bar plot
plt.figure(figsize=(5, 5))
topVideos = sns.barplot(x='Views_in_lakhs', y='Title', data=top10_videos, palette='Dark2')

# Set the title and labels
topVideos.set_title('Top 10 Videos by Views')
topVideos.set_xlabel('Views (in lakhs)')
topVideos.set_ylabel('Title')

# Set the x-axis labels to show each unit as one lakh
topVideos.set_xticks(range(0, int(top10_videos['Views_in_lakhs'].max()) + 2)) # Set ticks at each lakh

# Show the plot
plt.show()

all_video_data['Month'] = pd.to_datetime(all_video_data['Published_date']).dt.strftime('%b')
all_video_data

#to calculate the no.of videos uploaded in each month
videos_per_month = all_video_data.groupby('Month',as_index= False).size()
videos_per_month

#sorting
sort_order = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
videos_per_month.index = pd.CategoricalIndex(videos_per_month['Month'],categories = sort_order,ordered = True)
videos_per_month = videos_per_month.sort_index()
videos_per_month

import seaborn as sns
import matplotlib.pyplot as plt

# Create the bar plot
plt.figure(figsize=(5, 5))
Month_wise_uploads = sns.barplot(x='Month',y='size',data=videos_per_month, palette='Dark2')

# Set the title and labels
topVideos.set_title('Month wise uploaded videos')
topVideos.set_xlabel('Month')
topVideos.set_ylabel('No.of Videos Uploaded')

# Set the x-axis labels to show each unit as one lakh
topVideos.set_xticks(range(0, int(top10_videos['Views_in_lakhs'].max()) + 2)) # Set ticks at each lakh

# Show the plot
plt.show()

import pandas as pd

# Assuming all_video_data is your DataFrame with columns like 'Published_date', 'Views', 'Likes', 'Comments'

# Convert 'Published_date' to datetime format
all_video_data['Published_date'] = pd.to_datetime(all_video_data['Published_date'], errors='coerce')

# Check for any errors in datetime conversion
print(all_video_data['Published_date'].isnull().sum())

# Extract 'Year' from 'Published_date'
all_video_data['Year'] = all_video_data['Published_date'].dt.year

# Group by 'Year' to count videos uploaded
videos_per_year = all_video_data.groupby('Year').size().reset_index(name='Count')
videos_per_year

all_video_data['Year'] = all_video_data['Published_date'].dt.year
all_video_data

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming videos_per_year is your DataFrame with columns 'Year' and 'size'

# Create the bar plot
plt.figure(figsize=(5, 5))  # Adjust figsize as needed
sns.barplot(x='Year', y='Count', data=videos_per_year, palette='Dark2')

# Set the title and labels
plt.title('Year wise uploaded videos')
plt.xlabel('Year')
plt.ylabel('No. of Videos Uploaded')

# Adjust y-axis ticks to show 1 unit as 10 videos
plt.yticks(range(0, int(videos_per_year['Count'].max()) + 10, 10))

# Show the plot
plt.show()

"""# **Downloading the Extracted data**"""

#to download the extracted & processed data in csv file

all_video_data.to_csv('AlexTheAnalyst_channel.csv')